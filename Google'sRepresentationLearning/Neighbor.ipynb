{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb\n",
    "from CandidateExtraction import *\n",
    "import os\n",
    "from keras.models import load_model\n",
    "import json\n",
    "from Tesseract import *\n",
    "from keras.models import load_model\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "import sys\n",
    "import psutil\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataDir = os.listdir(\"/home/aman/Documents/Tally/Git-Document-AI/Document-AI/Google'sRepresentationLearning/Data\")\n",
    "# os.chdir(\"/home/aman/Documents/Tally/Git-Document-AI/Document-AI/Google'sRepresentationLearning/Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbourInfo(candidates, data):\n",
    "    file = open(\"/home/aman/Documents/Tally/Git-Document-AI/Document-AI/Google'sRepresentationLearning/Data/Models/wordEmbeddings.json\")\n",
    "    dict = json.load(file)\n",
    "\n",
    "    for df in candidates:\n",
    "        for col in dict.keys():\n",
    "            df[col] = 0\n",
    "            df[col+\"_X\"] = 0\n",
    "            df[col+\"_Y\"] = 0\n",
    "\n",
    "        for index in df.index:\n",
    "            Neighbours = []\n",
    "            X = df[\"x1\"][index] + df[\"x2\"][index]\n",
    "            Y = df[\"y1\"][index] + df[\"y2\"][index]\n",
    "            X/=2\n",
    "            Y/=2\n",
    "            for idx in data.index:\n",
    "                text = data[\"text\"][idx].lower()\n",
    "                X2 = data[\"X\"][idx]\n",
    "                Y2 = data[\"Y\"][idx]\n",
    "                if Y-Y2 >= 0 and Y-Y2 <= 0.1  and X2<X and text in dict.keys():\n",
    "                    df[text][index] = dict[text]\n",
    "                    df[text+\"_X\"][index] = X-X2\n",
    "                    df[text+\"_Y\"][index] = Y-Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCandidates(file):\n",
    "\n",
    "    data, candidateInfo = get_candidates(file)\n",
    "\n",
    "    data = data[[\"text\", \"X\", \"Y\"]]\n",
    "\n",
    "\n",
    "    getNeighbourInfo(candidateInfo, data)\n",
    "\n",
    "    return candidateInfo\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs = createCandidates(\"Images/20.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark():\n",
    "    \n",
    "    total_steps = 1000\n",
    "    progress_bar = tqdm(total=total_steps, ncols=80)\n",
    "    \n",
    "    n = input(\"Enter number of iterations : \")\n",
    "    \n",
    "    \n",
    "    start = time.time()\n",
    "    for i in range(int(n)):\n",
    "        dfs = createCandidates(\"Images/20.jpeg\")\n",
    "    end = time.time()\n",
    "    \n",
    "    inferenceTime = end-start\n",
    "    \n",
    "    cpuUsage = []\n",
    "    memoryUsage = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    step=1\n",
    "    for run in range(5):\n",
    "        cpuList = []\n",
    "        memoryList = []\n",
    "        process = psutil.Process()\n",
    "\n",
    "        for i in range(5):\n",
    "            cpuPercent = process.cpu_percent(interval=0.01)\n",
    "            memory = process.memory_info().rss\n",
    "            cpuList.append(cpuPercent)\n",
    "            memoryList.append(memory)\n",
    "\n",
    "            for j in range(int(n)):\n",
    "                dfs = createCandidates(\"Images/20.jpeg\")\n",
    "                \n",
    "                progress_bar.update(1)\n",
    "                elapsed_time = time.time() - start_time\n",
    "                remaining_time = elapsed_time / (step + 1) * (total_steps - step - 1)\n",
    "                progress_bar.set_postfix({'ETA': progress_bar.format_interval(remaining_time)})\n",
    "                step+=1\n",
    "                \n",
    "        avgCPU = sum(cpuList) / len(cpuList)\n",
    "        cpuUsage.append(avgCPU)\n",
    "        avgMemory = sum(memoryList) / len(memoryList)\n",
    "        memoryUsage.append(avgMemory)\n",
    "    \n",
    "    maxCPU = max(cpuUsage)\n",
    "    minCPU = min(cpuUsage)\n",
    "    \n",
    "    maxMemory = max(memoryUsage)\n",
    "    minMemory = min(memoryUsage)\n",
    "    \n",
    "    progress_bar.close()\n",
    "    \n",
    "    \n",
    "    return inferenceTime, maxCPU, minCPU, maxMemory, minMemory\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferenceTime, maxCPU, minCPU, maxMemory, minMemory = benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"BENCHMARK FOR 3 FIELDS \\n\\n\")\n",
    "# print(\"AVERAGE TIME TAKEN : \", \"{:.2f}\".format(inferenceTime), \"sec\")\n",
    "# print(\"MAX CPU USED: \", \"{:.2f}\".format(maxCPU), \"%\")\n",
    "# print(\"MAX MEMORY USED: \", maxMemory//(1024*1024), \"MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(\"/home/aman/Documents/Tally/Git-Document-AI/Document-AI/Google'sRepresentationLearning/Data/Images\")\n",
    "# imagesDir = os.listdir(\"/home/aman/Documents/Tally/Git-Document-AI/Document-AI/Google'sRepresentationLearning/Data/Images\")\n",
    "# total = 110\n",
    "# for file in imagesDir:\n",
    "#     print(total, \" Left\")\n",
    "#     total-=1\n",
    "#     dfs = createCandidates(file)\n",
    "#     os.chdir(\"/home/aman/Documents/Tally/Git-Document-AI/Document-AI/Google'sRepresentationLearning/Data/InvoiceNumberDataset\")\n",
    "#     dfs[0].to_csv(file + \".csv\")\n",
    "#     os.chdir(\"/home/aman/Documents/Tally/Git-Document-AI/Document-AI/Google'sRepresentationLearning/Data/InvoiceDateDataset\")\n",
    "#     dfs[1].to_csv(file + \".csv\")\n",
    "#     os.chdir(\"/home/aman/Documents/Tally/Git-Document-AI/Document-AI/Google'sRepresentationLearning/Data/TotalAmountDataset\")\n",
    "#     dfs[2].to_csv(file + \".csv\")\n",
    "#     os.chdir(\"/home/aman/Documents/Tally/Git-Document-AI/Document-AI/Google'sRepresentationLearning/Data/Images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
